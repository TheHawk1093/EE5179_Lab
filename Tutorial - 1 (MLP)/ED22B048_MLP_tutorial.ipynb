{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VGfYDqznAGlP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mtfn0y2xAHOw"
      },
      "outputs": [],
      "source": [
        "class MyNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=20, hidden_dim1=64, hidden_dim2=128, hidden_dim3=64, output_dim=1):\n",
        "        super(MyNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.layer2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        self.layer3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
        "        self.output_layer = nn.Linear(hidden_dim1 + hidden_dim3, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First layer\n",
        "        out1 = self.relu(self.layer1(x))\n",
        "\n",
        "        # Second layer\n",
        "        out2 = self.relu(self.layer2(out1))\n",
        "\n",
        "        # Third layer\n",
        "        out3 = self.relu(self.layer3(out2))\n",
        "\n",
        "        # Concatenate outputs of the 1st and 3rd layers\n",
        "        concatenated_output = torch.cat((out1, out3), dim=1)\n",
        "\n",
        "        # Output layer\n",
        "        output = self.sigmoid(self.output_layer(concatenated_output))\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-SrevOlfAduV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(32, 20)  # Batch of 32 samples with 20 features each\n",
        "model = MyNetwork()\n",
        "output = model(x)\n",
        "print(output.shape)  # Should print torch.Size([32, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hBc8ju9bAlge"
      },
      "outputs": [],
      "source": [
        "def generate_synthetic_data(num_samples=1000, input_dim=20):\n",
        "    # Generate random features\n",
        "    X = torch.randn(num_samples, input_dim)\n",
        "\n",
        "    # Generate random labels (0 or 1)\n",
        "    y = torch.randint(0, 2, (num_samples, 1)).float()\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EslO0JQFCx5L"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=10, device='cpu'):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) #Ensure that everything is on the same device\n",
        "\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels) # Add the loss and that can be customised\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n",
        "\n",
        "    print('Training complete.')\n",
        "\n",
        "\n",
        "#If the network is not able to learn the training example we will observe that the loss is not decreasing and in such cases we can try to change the learning rate or use a different optimizer\n",
        "#the colab environment may crash at times so it is important to save the weights and other params after certain number of epochs so we can directly resume training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mIhT0QnE0_8",
        "outputId": "4073ee5b-27ec-424a-8283-1b99f00dc63b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kDOo1fbDtRE",
        "outputId": "9aa98a23-33ef-408e-f5ff-970324031d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.6957\n",
            "Epoch [2/10], Loss: 0.6865\n",
            "Epoch [3/10], Loss: 0.6828\n",
            "Epoch [4/10], Loss: 0.6739\n",
            "Epoch [5/10], Loss: 0.6590\n",
            "Epoch [6/10], Loss: 0.6438\n",
            "Epoch [7/10], Loss: 0.6138\n",
            "Epoch [8/10], Loss: 0.5772\n",
            "Epoch [9/10], Loss: 0.5288\n",
            "Epoch [10/10], Loss: 0.4865\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Hyperparameters\n",
        "input_dim = 20\n",
        "hidden_dim1 = 64\n",
        "hidden_dim2 = 128\n",
        "hidden_dim3 = 64\n",
        "output_dim = 1\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Initialize the model, criterion, and optimizer\n",
        "model = MyNetwork(input_dim=input_dim, hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2, hidden_dim3=hidden_dim3, output_dim=output_dim).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # We can use any other optimizer apart from Adam\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = generate_synthetic_data(num_samples=1000, input_dim=input_dim)\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = TensorDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, dataloader, criterion, optimizer, num_epochs=num_epochs, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bHZjzCrBD1sq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwFgNarPFaPE",
        "outputId": "2d050e14-7c19-4204-c98c-acf0e9d58b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 55.50%\n",
            "Predicted label: 0.0\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, dataloader, device='cpu'):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # No need to calculate gradients during evaluation\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs > 0.5).float()  # Apply threshold for binary classification\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "def make_inference(model, input_data, device='cpu'):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    input_data = input_data.to(device)\n",
        "    with torch.no_grad():  # No need to calculate gradients during inference\n",
        "        output = model(input_data)\n",
        "        predicted = (output > 0.5).float()  # Apply threshold for binary classification\n",
        "    return predicted\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Generate synthetic test data (similar to training data)\n",
        "X_test, y_test = generate_synthetic_data(num_samples=200, input_dim=input_dim)\n",
        "\n",
        "# Create DataLoader for test data\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "evaluate_model(model, test_dataloader, device=device)\n",
        "\n",
        "# Example of making predictions on a new input\n",
        "new_input = torch.randn(1, input_dim)  # Generate a random new input sample\n",
        "predicted_label = make_inference(model, new_input, device=device)\n",
        "print(f'Predicted label: {predicted_label.item()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jANt5cyHICHG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
